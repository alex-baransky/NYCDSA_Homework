---
title: "Tree_Methods_HW"
author: "Alex Baransky"
output: html_document
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message=FALSE)
```

## Question #1: Orange Juice Data
**Purpose: Demonstrating Understanding of how to run the models**

1. **Load: **Load the *OJ* dataset from the **ISLR** library into your workspace. The data contains 1,070 purchases where the customer either purchased Citrus Hill or Minute Maid orange juice. A number of characteristics of the customer and product are recorded.
```{r}
library(ISLR)
data(OJ)
```

2. **Model a Tree: **Construct an initial decision tree predicting *Purchase* from all other variables in the training dataset.
    + Split the data into a training and test set with an 80% - 20% split, respectively.
    + Define splits based upon the Gini Coefficien
    + What are the training and testing accuracies?
```{r}
library(tree)
head(OJ)
set.seed(0)
train_index = sample(1:nrow(OJ), .8*nrow(OJ))
train = OJ[train_index,]
test = OJ[-train_index, -1] #Test response.

tree.OJ = tree(Purchase ~ ., split = "gini", data = train)
plot(tree.OJ)
text(tree.OJ, pretty = 0)
summary(tree.OJ)

predict.OJ = predict(tree.OJ, test, type = "class")
predict.OJ
table(predict.OJ, OJ[-train_index, 'Purchase'])
(106+59)/214
```

3. **Cross_Validate: **Cross-Validate your tree using *prune.misclass* as your cost-complexity pruning function.
```{r}
cv.OJ = cv.tree(tree.OJ, FUN = prune.misclass)
```

4. **Visualize: **Visualize your CV results plotting misclassified observations against:
    + terminal nodes
    + alpha values
```{r}
names(cv.OJ)
cv.OJ
par(mfrow = c(1, 2))
plot(cv.OJ$size, cv.OJ$dev, type = "b",
     xlab = "Terminal Nodes", ylab = "Misclassified Observations")
plot(cv.OJ$k, cv.OJ$dev, type = "b",
     xlab = "Alpha", ylab = "Misclassified Observations")
```

5. **Prune and Compare**
    + Prune your tree based on the cross-validated results.
    + What are the training and testing accuracies of your pruned tree?
    + Visualize your pruned tree.
    + Why are the test set predictions more accurate for the pruned tree than those for the initial tree?
```{r}
#### Accuracy is worse?????
pruned.OJ = prune.misclass(tree.OJ, best = 9)
summary(pruned.OJ)
predict.prunedOJ = predict(pruned.OJ, test, type = "class")
table(predict.prunedOJ, OJ[-train_index, 'Purchase'])
(114+57)/214

# Pruned tree prediction is more accurate because original tree was overfit
```

6. **Model a Forest: **Construct an initial random forest predicting *Purchase* using the default settings. (This will create 500 trees)
    + Give the accuracy of the training set (the oob accuracy) and the test set.
    + Which variable is aiding the most in classifying the orange juice purchases?
```{r}
library(randomForest)

set.seed(0)
rf.OJ = randomForest(Purchase ~ ., data = OJ, subset = train_index)
rf.OJ

predict.rf = predict(rf.OJ, test, type='class')
table(predict.rf, OJ[-train_index, 'Purchase'])
(114+60)/214

rf.OJ$importance
# LoyalCH
```

7. **Tune: **Vary the number of variables considered as candidates at each node split in the random forest procedure (from one to all predictors). Record the out-of-bag error rates for each of these random forests on the training set.(**Hint**  You will want to record the error rate instead of the MSE since this is a classification problem. If you are modifying class code, try using the code snippet *fit$error.rate[500, 1]*)
    + Visualize the out-of-bag error rates as they change with the number of variables considered at each split
    + What is the maximum accuracy among your random forests on the training set? How many variables were considered at each split in the best random forest.
    + What is the oob accuracy of the bagged model on the training set? How many variables were considered at each split in this bagged model?
```{r}
### missing bagged model?
set.seed(0)
oob.err = numeric(17)
for (mtry in 1:17) {
  fit = randomForest(Purchase ~ ., data = train, mtry = mtry)
  oob.err[mtry] = fit$err.rate[500, 1]
  cat("We're performing iteration", mtry, "\n")
}

plot(oob.err, type = 'b')

best.fit = randomForest(Purchase ~ ., data = train, mtry = 2)
best.fit

(455+235)/856
best.fit$err.rate[500, 1]
```

8. **Compare: **What is the accuracy of the best random forest from Part 7 on the test set? What is the accuracy of the bagged model on the test set?
```{r}
predict.best.fit = predict(best.fit, test, type='class')
table(predict.best.fit, OJ[-train_index, 'Purchase'])
(118+58)/214
```


## Question #2: Machine Learning Theory
**Demonstrate theory of lecture**

1. **Greedy: **What does it mean to say recursive binary splitting is a greedy process?
```{text}

```

2. **Metrics: **What metric is commonly used to determine the optimal split in a regression trees? What about in a classification tree? Explain these metrics.
```{text}

```

## Question #3: Challenge Questions
**Purpose: Push yourself for more advanced topics**

1. **Regularization: **Try to select the features with lasso, and then use the selected features to train the random forest. You might want to redo the cross-validation to select mtry now that the features are less. Is the result better than without lasso? Try to be careful when answering the last question.
```{r}

```

2. **Transform: **In order to boost with classification trees, we need to do a bit of data munging to transform the response variable. You may use the following lines of code to produce the copies of your dataset *OJ.train.indicator* and *OJ.test.indicator* that have a transformed response variable. (**NB:** You must replace *OJ.train* and *OJ.test* with whatever names you used in your own code)
```{r}
# OJ.train.indicator = OJ.train
# OJ.test.indicator = OJ.test
# OJ.train.indicator$Purchase = as.vector(OJ.train$Purchase, mode = 'numeric') - 1
# OJ.test.indicator$Purchase = as.vector(OJ.test$Purchase, mode = 'numeric') - 1

```

3. **Boosted Model: **Construct an initial boosted model on the training set that uses all of the following settings at once
    + The Bernoulli Distribution
    + 10,000 Trees
    + An interaction depth of 4
    + A shrinkage of parameter 0.001
```{r}

```

4. **Predict: **Predict your test set observations using the initial boosted model across up to 10,000 trees, considering groups of 100 trees at a time. (**Hint:** Use *type = 'response'* and round your predictions).
```{r}

```

5. **Evaluate: **Calculate and store the accuracy for each of the 100 models considered in Part 4. What is the minimum number of trees required to reach the maximum accuracy?
```{r}

```

6. **Visualize: **Plot the accuracies found in Part 5 against the number of trees. Add the following to the plot:
    + A horizontal line marking the best boosted accuracy on the test set
    + A horizontal line marking the best random forest accuracy on the test set
    + A horizontal line marking the best pruned tree accuracy on the test set.
```{r}

```

