---
title: "Regularization_and_Cross_Validation_HW"
author: "Alex Baransky"
output: html_document
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message=FALSE)
```

## Question #1: Ridge Regression
**Purpose: Demonstrate Understanding to Run Model**

1. Load: Load in the Prostate.txt dataset into your workspace. This dataset comes from a study by Stamey et a. (1989) of prostate cancer, measuring the correlation between the level of a prostate-speci c antigen and some covariates. The included variables are the log-cancer volume, log-prostate weight, age of patient, log-amount of benign hyperplasia, seminal vesicle invasion, log-capsular penetration, Gleason score, and percent of Gleason scores 4 or 5; the response variable is the log-psa.
```{r}
prostate = read.table("https://s3.amazonaws.com/nycdsabt01/Prostate.txt", header = TRUE)

```

2. Train test split: Create an 80% - 20% train-test split with your data. Please use set.seed(0) so the results will be reproducible.
```{r}
set.seed(0)
train = sample(1:nrow(prostate), 0.8*nrow(prostate))
test = (-train)

```

3.Fit a model: Use library glmnet to fit a ridge regression model on your training data by setting up a grid of lambda values 10^seq(5, -2, length = 100). Save the coefficients of these models in an object.
```{r}
library(glmnet)
library(ISLR)
x = model.matrix(lpsa ~ ., prostate[train, ])[, -1]
y = prostate$lpsa[train]
grid = 10^seq(5, -2, length = 100)
ridge.models = glmnet(x, y, alpha = 0, lambda = grid)
coefs = coef(ridge.models)
```

4. Visualization: Plot the coefficients of these models and comment on the shrinkage.
```{r}
plot(ridge.models, xvar = "lambda", label = TRUE, main = "Ridge Regression")

```

5. Cross Validation: Perform 10-fold cross validation and use set.seed(0) on your training data with the grid of lambda values defined in part 2. Save the output as an object.
```{r}
set.seed(0)
cv.ridge.out = cv.glmnet(x, y,
                         lambda = grid, alpha = 0, nfolds = 10)

```

6. Visualization: Create and interpret a plot associated with the 10-fold cross validation completed in part 4.
```{r}
plot(cv.ridge.out, main = "Ridge Regression\n")

```

7. Results: What is the best lambda? 
```{r}
best.lambda = cv.ridge.out$lambda.min
best.lambda
log(best.lambda)

```

8. Fit a model: Fit a ridge regression model using the best lambda on the test dataset. What is the test MSE associated with the best lambda value?
```{r}
x.test = model.matrix(lpsa ~ ., prostate[test, ])[, -1]
y.test = prostate$lpsa[test]
ridge.models.train = glmnet(x.test, y.test, alpha = 0, lambda = grid)
ridge.bestlambdatrain = predict(ridge.models.train, s = best.lambda, newx = x.test)
summary(ridge.bestlambdatrain)
mean((ridge.bestlambdatrain - y.test)^2)
```

9. Refit a model & Results: Refit the ridge regression using the best lambda in your original dataset. Briefly comment on the coefficient estimates and MSE. Why is this MSE smaller than the test MSE you found in part 7?
```{r}
# ????

```

## Question #2: Machine Learning Theory
**Purpose: Demonstrate Theory of Lecture Material**

1. Lambda: What is lambda in Ridge, Lasso and Elastic Net regression? What is its function?
 
```{r}
# Lambda is a tuning parameter, it is the sum of the squared coefficient estimates. It is used to scale the Beta coefficients so that there is a penalty for large betas when trying to minimize the RSS.

```

2. Cross Validation: What is the purpose of doing cross validation? Explain the k-fold cross validation process.
```{r}
# Cross validation is used to test how well a ML model can predict new values with new data. The original training data is split so that some of it can be used to train the model and the other part can be used to test how well the model does. K-fold CV is when you split the data into k equal parts. Over k times, one of the subsets is used for testing while the other k-1 are combined and used for training. Then the resulting error of all trials is averaged.

```

3. Cross Validation: How should we choose cross validation folds typically? What does it mean when we choose a larger number of k-fold?
```{r}
# Typically k should be 5 or 10. The larger k is, the smaller the subset of the data to be tested and the larger the data to be used for training. This will lower the vairance but introduce more bias.

```


## Question #3:Challenge Questions- Lasso Regression

1. Lasso Regression: Repeat the entire analysis performed in question #1, but use the lasso regression method this time.
```{r}
set.seed(0)
lasso.models = glmnet(x, y, alpha = 1, lambda = grid)
lasso_coefs = coef(ridge.models)

plot(lasso.models, xvar = "lambda", label = TRUE, main = "Lasso Regression")

cv.lasso.out = cv.glmnet(x, y,
                         lambda = grid, alpha = 1, nfolds = 10)
plot(cv.lasso.out, main = "Lasso Regression\n")

best.lambda.lasso = cv.lasso.out$lambda.min
best.lambda.lasso
log(best.lambda.lasso)

lasso.models.train = glmnet(x.test, y.test, alpha = 1, lambda = grid)
lasso.bestlambdatrain = predict(lasso.models.train, s = best.lambda.lasso, newx = x.test)
summary(lasso.bestlambdatrain)
mean((lasso.bestlambdatrain - y.test)^2)

```

2. Compare: Compare your final ridge and lasso models. Which one would you choose to use? Why?
```{r}


```


