---
title: "Generalized_Linear_Models_HW"
author: "Alex Baransky"
output: html_document
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message=FALSE)
```

## Question 1: Birdkeeping and Lung Cancer
1. Load the **Sleuth2** library and extract the *case2002* dataset. This dataset reports results of a survey conducted from 1972 to 1981 in the Netherlands aiming to see if birdkeeping is a risk factor for lung cancer. Variables include whether or not an individual had lung cancer, whether or not they were birdkeeping, their gender, socioeconomic status, age, years of smoking, and average rate of smoking.
```{r}
library(Sleuth2)
data(case2002)
?case2002
```

2. Create a scatterplot matrix of the continuous variables colored by whether or not an individual had lung cancer. Which variables may be problematic for our model?
```{r}
plot(~AG + YR + CD, data=case2002, col=case2002$LC)
# AG and YR seem to be correlated
```

3. Fit a logistic regression predicting whether or not an individual has lung cancer that includes all variables in the model.
```{r}
logit.all = glm(LC ~ .,
                    family = "binomial",
                    data = case2002)
```

4. Conduct and interpret an overall goodness of fit test for the model created in Part 3.
```{r}
pchisq(logit.all$deviance, logit.all$df.residual, lower.tail = FALSE)
```

5. Interpret the coefficient of gender.
```{r}
logit.all$coefficients
# A coefficient of .56127 is the effect on the rate of change of the log odds. This means being female increases odds by 1.75
```

6. Fit a logistic regression predicting whether or not an individual has lung cancer that includes all variables in the model except the birdkeeping indicator. Conduct and interpret an overall goodness of fit test for the new model.
```{r}
logit.noBK = glm(LC ~ . - BK,
                    family = "binomial",
                    data = case2002)
pchisq(logit.noBK$deviance, logit.noBK$df.residual, lower.tail = FALSE)
```

7. Conduct and interpret a drop in deviance test comparing the two models youâ€™ve created thus far. Which would you keep in favor of the other?
```{r}
full_deviance = logit.all$deviance
full_df = logit.all$df.residual
noBK_deviance = logit.noBK$deviance
noBK_df = logit.noBK$df.residual

pchisq(noBK_deviance - full_deviance,
       noBK_df - full_df,
       lower.tail = FALSE)
anova(logit.noBK, logit.all, test = "Chisq")

# The P value is very small, meaning we have evidence to conclude that the model with all features is preferable to the model with BK removed
```

8. Fit a logistic regression predicting whether or not an individual has lung cancer based only on whether or not they have birds and the number of years they have been smoking.
```{r}
logit.bird.smoke = glm(LC ~ BK + YR,
                    family = "binomial",
                    data = case2002)
summary(logit.bird.smoke)
```

9. Conduct and interpret a drop in deviance test comparing the newest model to the original model. Which would you keep in favor of the other?
```{r}
anova(logit.bird.smoke, logit.all, test = "Chisq")
# The P value is large indicating that there is not enough evidence to conclude that the reduced model is insufficient
```

10. Compare the models across:
    + AIC
    + BIC
    + R^2_dev
    + Give an argument for choosing the model created in Part 8
```{r}
AIC(logit.all, logit.noBK, logit.bird.smoke)
BIC(logit.all, logit.noBK, logit.bird.smoke)
logit.all$deviance
logit.noBK$deviance
logit.bird.smoke$deviance

# The model from 8 has slightly higher deviance than the full model, but it has lower AIC and BIC scores.
```

11. Using the model created in Part 8, predict:
    + A The probability of having lung cancer for an individual with an average number of years smoking with and without birds within their household.
    + B The probability of having lung cancer for an individual with no years prior smoking with and without birds within their household.
```{r}
newdata_avg = with(case2002, data.frame(YR = mean(YR),
                                       BK = c('NoBird', 'Bird')))
cbind(newdata_avg, "Prob. Cancer" = predict(logit.bird.smoke, newdata_avg, type = "response"))

newdata_nosmoke = with(case2002, data.frame(YR = 0,
                                       BK = c('NoBird', 'Bird')))
cbind(newdata_nosmoke, "Prob. Cancer" = predict(logit.bird.smoke, newdata_nosmoke, type = "response"))
```
12. Use the model created in part 8 to classify the observations in your dataset as having or not having lung cancer. Comment on how well the model performs as compared to the baseline.
```{r}
cancer.predicted = round(logit.bird.smoke$fitted.values)
table(truth = case2002$LC, prediction = cancer.predicted)
```


## Question 2: Machine Learning Theory
1. How do we estimate the coefficients in a logistic regression model?
```{text}
# We use a sigmoid to map the linear function that predicts y to the probability that y will be one of two binary classes
```
2. How do we use the logistic model to predict binary classes?
```{text}
# We use the link function to transfor the linear equation into coefficients that change the odds that y will belong to one class or the other
```
3. Why do we use the Wald Test?
```{text}
# Because we are comparing predicted values to true values?
```
4. Describe how you can compare two logistic models statistically?
```{text}
# Using a chisquare test, you can test two models to see if the deviance is statistically different between them. This will show whether a model
# with reduced features is sufficient or not to predict the classes coreectly
```

## Question 3: Bonus Question
1. Suppose we would like to train a logistic regression to predict whether or not an individual has lung cancer based only on the number of years they have been smoking. Implement the **negative log-likelihood function** for it.
```{r}
neg_log_likelihood<-function(intercept, slope){
    # Your code here
}

#If you implement correctly, the code below:
install.packages('optimx')
library(optimx)
target <- function(pair) neg_log_likelihood(pair[1], pair[2])
ans <- optimx(par=c(-1,-1), fn = target)
print(ans$p1[1])
print(ans$p2[1])

#Should give the intercept and the slope very close to the result from:

model = glm(LC ~ YR, family = "binomial", data = case2002)
summary(model) 
```

